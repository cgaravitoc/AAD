---
title: "Taller 3 - Análisis Avanzado de Datos"
author: "Carlos Garavito y Cristhian Zamora"
date: "2023-05-05"
output:
  rmdformats::downcute:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

# Análisis Avanzado de Datos - Taller 3

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE, include=FALSE}
library(readr)
require(plyr)
library(knitr)
library(dplyr)
library(tibble)
library(ggthemes)
library(tidyr)
library(corrplot)
library(factoextra)
library(readxl)
require(car)
library(ISLR2)
library(splines)
library(boot)
library(glmnet)
library(caret)
library(utils)
options(warn=-1)
options(dplyr.summarise.inform = FALSE)
```


## Problema 1 
Una familia de distribuciones $P_{\theta}$ con $\theta \in \Theta$ pertenece a la familia exponencial de distribuciones si su $fmp/fdp$ puede escribirse como:

$$
p(x| \eta) = h(x) \exp(\eta(\theta)t(x)-a(\theta))
$$
Para funciones reales $h(x)$, $a(\theta)$ y $t(x)$. Muestre que tanto la distribución Bernoulli (utilizada para la regresión logística), la distribución normal (utilizada en la regresión lineal) y la distribución Poisson (utilizada en la regresión Poisson sobre conteos) pertenecen a esta familia de distribuciones.

### Distribución Bernoulli 
La función de masa de probabilidad de la distribución Bernoulli está dada por: 

$$
P_{Bernoulli}(x) = p^n (1-p)^{1-n}.
$$
Luego, sacando provecho de la propiedad inversa de la función exponencial y la función logaritmo, se tiene: 

$$
\begin{aligned}
  P_{Bernoulli} & = \alpha^x (1-\alpha)^{1-x}, \\
    & = \exp\left\{log\left[ \alpha^x (1-\alpha)^{1-x}\right]\right\}, \\
    & = \exp\left\{log(\alpha^x) + log[(1-x)^{1-x}]\right\}, \\
    & = \exp\left\{x\cdot log(\alpha) + (1-x) \cdot log(1-\alpha)\right\}, \\
    & = \exp\left\{x\cdot log(\alpha)+ log(1-\alpha) - x\cdot log(1-\alpha)\right\}, \\
    & = \exp\left\{x [log(\alpha) - log(1-\alpha)] + log(1-\alpha) \right\},\\
    & = \exp\left\{x \cdot log\left( \frac{\alpha}{1-\alpha} \right) + log(1-\alpha) \right\};
\end{aligned}
$$
donde, haciendo $h(x) = 1$, $\eta(\theta) = log\left( \frac{\alpha}{1-\alpha} \right)$, $t(x) = x$ y $a(\theta) = log(1-\alpha)$, se muestra que la distribución normal es una familia de distribución exponencial. 

### Distribución normal
La función de densidad para una distribución normal, se define como: 

$$
  P_{normal} = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp{\left(\frac{-(x-\mu)^2}{2\sigma^2}\right)}. \\
  
$$
Luego, expandiendo el binomio del argumento de la función exponencial, se recibe: 

$$
\begin{aligned}
  P_{normal} &=  \frac{1}{\sqrt{2 \pi \sigma^2}} \exp{\left(\frac{-(x-\mu)^2}{2\sigma^2}\right)},\\
  P_{normal} &=  \frac{1}{\sigma \sqrt{2 \pi}} \exp{\left(\frac{-(x-\mu)^2}{2\sigma^2}\right)},\\
  P_{normal} &=  \frac{1}{\sqrt{2 \pi}} \exp\left({\log{(\sigma^{-1})}}\right)  \exp{\left(\frac{-(x-\mu)^2}{2\sigma^2}\right)},\\
  P_{normal} &= \frac{1}{\sqrt{2 \pi}} \exp{\left(-\log(\sigma) + \frac{-(x-\mu)^2}{2\sigma^2}\right)},\\
  P_{normal} &= \frac{1}{\sqrt{2 \pi}} \exp{\left(-\log(\sigma) - \frac{(x^2-2x\mu+\mu^2)}{2\sigma^2}\right)},\\
  P_{normal} &= \frac{1}{\sqrt{2 \pi}} \exp{\left(-\log(\sigma) - \frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2}\right)},\\
\end{aligned}
$$
reorganizando los términos, 

$$
\begin{aligned}
  P_{normal} &= \frac{1}{\sqrt{2 \pi}} \exp{\left(-\log(\sigma) - \frac{\mu^2}{2\sigma^2} -  \frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} \right)}, \\ 
\end{aligned}
$$
y escribiendo en notación matricial se tiene: 
$$
  \begin{aligned}
  P_{normal} &= \frac{1}{\sqrt{2 \pi}} \exp{\left(\boldsymbol{t(x)}^T\boldsymbol{\eta(\theta)} -\alpha(\theta) \right)}, \\ 
\end{aligned}
$$
donde,


\begin{equation}
t(x) = \begin{bmatrix}
  x \\
  x^2
\end{bmatrix},
\eta(\theta) = \begin{bmatrix}
  \frac{\mu}{\sigma^2} \\
  -\frac{1}{2\sigma^2}
\end{bmatrix}, 
\alpha(\theta) = \log(\sigma) + \frac{\mu^2}{2\sigma^2}, \quad
h(x) = \frac{1}{\sqrt{2\pi}}.
\end{equation}


### Distribución Poisson
La función de masa probabilidad para la distribución de Poisson, se escribe de la forma: 

$$
\begin{aligned}
  P_{poisson} &= \frac{\lambda^x \exp{(-\lambda)}}{x!}.
\end{aligned}
$$
Luego, sacando provecho de la propiedad inversa entre la función exponencial y logaritmo, se tiene: 

$$
\begin{aligned}
  P_{poisson} &= \frac{\lambda^x \exp{(-\lambda)}}{x!}, \\ 
  P_{poisson} &= \frac{\exp\left(x\log(\lambda)\right) \exp{(-\lambda)}}{x!}, \\
  P_{poisson} &= \frac{1}{x!} \exp\left(x \log(\lambda) -\lambda \right).
\end{aligned}
$$
Luego, si $h(x) = \frac{1}{x!}$, $\eta(\theta) = log(\lambda)$, $t(x) = x$ y $\alpha(\theta) = \lambda$, se da cuenta que la distribución de Poisson hace parte de la familia de distribuciones exponencial. 


## Problema 2
La Universidad de California Irvine (UCI) tiene un repositorio de datos de ejemplo para el uso de machine learning y aprendizaje estadístico. Uno de los conjuntos de datos es el denominado Heart Disease.

Con el conjunto de datos completo, construya un modelo de regresión logístico con función de enlace logit tomando como respuesta la presencia de la enfermedad cardiaca, use las demás variables como explicativas en el modelo de regresión. Revise las URL dadas para la definición de cada una de las variables y note que debe obtener la variable respuesta categorizando una de las variables del conjunto de datos. Siga los siguientes pasos en la realización del ejercicio:

### 1. Imputar datos
El conjunto de datos tiene datos perdidos en algunas variables. Estos están notados con un ?. Impute los valores perdidos como la mediana de los datos para las variables correspondientes.


En primer lugar cargamos los datos desde la URL indicada:
```{r}
# Definir la URL del archivo de datos
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"

# Leer los datos desde la URL
datos <- read.table(url, sep = ",")

# Ajustar varaible objetivo

datos$V14 <- (datos$V14 > 0)*1

# Imprimir los primeros registros de los datos
head(datos)

```

Como se indicó, los datos nulos se identifican mediante el simbolo ?, por lo tanto se remplaza dicho simbolo con nulos.
```{r}
datos[datos == "?"] <- NA
```

La libreria VIM permite vizualizar la participación de de los datos nulos en cada una de las varaibles. Se observa que la varaible V12 (ca: number of major vessels (0-3) colored by flourosopy) es la que mayor paricipación de nulos tiene con un 13.2%, seguida de la varaible V13 (thal: 3 = normal; 6 = fixed defect; 7 = reversable defect) con un 6.6%.


```{r}
#install.packages("VIM")
library(VIM)
aggr(datos,numbers=T,sortVar=T)

```

Se imputan los valores perdidos como la mediana de los datos para las variables V12 y V13 respectivamente.
```{r}
datos$V12 <- as.numeric(datos$V12)
datos$V13 <- as.numeric(datos$V13)
datos$V12[is.na(datos$V12)] <- median(datos$V12, na.rm = TRUE)
datos$V13[is.na(datos$V13)] <- median(datos$V13, na.rm = TRUE)
```

### 2. Revisar las distribuciones bivariadas 
Revise la distribución de la variable respuesta para cada una de las covariables categoricas de manera bivariada. ¿observa algún inconveniente con alguna de las variables al hacer el análisis?.


```{r,echo=FALSE, include=FALSE}
datos2 <- datos

datos2$V14<- mapvalues(datos2$V14, from=c(0,1), to=c('no disease','disease'))  
datos2$V2<- mapvalues(datos2$V2, from=c(0,1), to=c('female','male'))  
datos2$V3<- mapvalues(datos2$V3, from=c(1,2,3,4), to=c('typical_angina','atypical angina', 'non_anginal_pain', 'asymptomatic'))
datos2$V6<- mapvalues(datos2$V6, from=c(0,1), to=c('false','true'))
datos2$V7<- mapvalues(datos2$V7, from=c(0,1,2), to=c('normal','ST_wave_abnormality', 'ventricular_hypertrophy'))
datos2$V9<- mapvalues(datos2$V9, from=c(0,1), to=c('no','yes'))  
datos2$V11<- mapvalues(datos2$V11, from=c(1,2,3), to=c('upsloping','flat', 'downsloping'))  
datos2$V13<- mapvalues(datos2$V13, from=c(3.0,6.0,7.0), to=c('normal','fixed_defect', 'reversable_defect'))  

datos2 <- datos2 %>% dplyr:::rename(sex=V2 , chest_pain_type=V3,  fbs=V6, resting_ecg_results=V7, exercise_induced_angina=V9, slope=V11,  num_major_vessels=V12, thal=V13, heart_disease=V14)
```


Al realizar las distribuciones bivariadas de las variables categóricas con respecto a la variable objetivo se observa:

* Al parecer hay más incidencia de enfermedad cardiaca en el género femenino.

* Al parecer ser asintomático en el tipo de dolor en el pecho se relaciona con presencia de enfermedad cardiaca

* La variable fbs (fasting blood sugar > 120 mg/dl) al parecer no tiene ninguna relación con la presencia de enfermedad cardiaca

* Para la variable resting electrocardiographic results el valor ST-T wave abnormality parece tener relación con la presencia de enfermedad cardiaca.

*	Para la variable exercise induced angina el valor yes parece tener relación con la presencia de enfermedad cardiaca

*	Para la variable slope of the peak exercise el valor upsloping parece tener relación con la presencia de enfermedad cardiaca

* A medida que los valores de la variable number of major vessels aumentan parece aumentar la presencia de enfermedad cardiaca

* Para la variable thal el valor normal parece relacionarse con la ausencia de enfermedad cardiaca


```{r}
groups <- c(quo(sex), quo(chest_pain_type), quo(fbs), quo(resting_ecg_results), quo(exercise_induced_angina), quo(slope), quo(num_major_vessels), quo(thal)) 
for (i in seq_along(groups)) {
  agg_tbl  <- datos2 %>% group_by(!!groups[[i]], heart_disease) %>% # Unquote with !!
    summarise(total_count=n())%>% as.data.frame()
  
  plt <- ggplot(agg_tbl,
       aes(x = !!groups[[i]], y = total_count, fill = heart_disease,label=total_count)) +
       geom_col(position = "fill")
  print(plt)
}
```


### 3. Modelo bivariado
Calcule manualmente (como lo vimos en clase, a partir de la tabla de contingencia), los parámetros estimados de regresión logística considerando únicamente la variable fbs
(glucemia en ayunas) y la variable respuesta. Verifique el resultado ajustando el glm correspondiente.

```{r}
table(datos2$fbs, datos2$heart_disease)
```

### Modelo Multivariado
Text goes here...

### Visualización probabilidades
Text goes here...

## Problema 3
El conjunto de datos `AAD-taller03.xlsx` contiene la predicción de incumplimiento de pago de tarjeta de crédito bajo dos modelos logísticos diferentes para un total de 9080 clientes. Se cuenta además con la variable de incumplimiento observada al finalizar el periodo. ¿Cuál de los dos modelos logísticos tiene mayor poder de predicción? Explique con fundamento estadístico su resultado.

```{r}
data_score <- read_excel("AAD-taller03.xlsx", sheet = "Sheet1")
head(data_score)
```
Se validan los valores máximos, mínimos y promedios de ambos score, donde se recibe,

```{r}
min_score <- c(min(data_score$ScoreLogisticoA), min(data_score$ScoreLogisticoB))
max_score <- c(max(data_score$ScoreLogisticoA), max(data_score$ScoreLogisticoB))
mean_score <- c(mean(data_score$ScoreLogisticoA), mean(data_score$ScoreLogisticoB))
mean_score_class1 <- c(mean(data_score$ScoreLogisticoA[data_score$Incumplimiento == 1]), mean(data_score$ScoreLogisticoB[data_score$Incumplimiento == 1]) )
mean_score_class0 <- c(mean(data_score$ScoreLogisticoA[data_score$Incumplimiento == 0]), mean(data_score$ScoreLogisticoB[data_score$Incumplimiento == 0]) )

resume_data <- data.frame(Score = c("ScoreLogisticoA", "ScoreLogisticoB"), 
                          min_score = min_score, 
                          max_score = max_score, 
                          mean_score = mean_score, 
                          mean_score_class1 = mean_score_class1, 
                          mean_score_class0 = mean_score_class0)

data.frame(t(resume_data))

```
En la tabla se puede observar que en ambos casos, el score está en el rango $[0,1]$. Además, también se aprecia que el valor promedio de la clase 0 se encuentra por debajo del valor promedio del score total y, de manera análoga, el valor promedio de la clase 1 se encuentra por encima de valor promedio del score total. Así, se evidencia que el valor de activación para la clasificación corresponde al valor promedio de cada caso. En ese orden de ideas, en la tabla de datos original se incluye la variable respuesta de cada score. 
```{r}
treshold_A <- mean(data_score$ScoreLogisticoA)
treshold_B <- mean(data_score$ScoreLogisticoB)

data_score$pred_A <- factor(ifelse(data_score$ScoreLogisticoA > treshold_A, 1, 0))
data_score$pred_B <- factor(ifelse(data_score$ScoreLogisticoB > treshold_A, 1, 0))
data_score$Incumplimiento <- factor(data_score$Incumplimiento)

data_score
```
Calculando la métricas de rendimiento para el modelo ScoreLogisticoA, se encuentra: 

```{r}
#Creating confusion matrix
confusionMatrixA <- caret::confusionMatrix(data=data_score$pred_A, reference = data_score$Incumplimiento, positive = "1")

#Display results 
confusionMatrixA
```
De la misma manera, calculando la métricas de rendimiento para el modelo ScoreLogisticoB, se encuentra: 

```{r}
#Creating confusion matrix
confusionMatrixB <- caret::confusionMatrix(data=data_score$pred_B, reference = data_score$Incumplimiento, positive = "1")

#Display results 
confusionMatrixB
```
De esta manera, se puede ver que el modelo ScoreLogisticoA tiene una precisión del 59%, mientras que el ScoreLogisticoB tiene una precisión del 47%. Además, de la lectura de las matrices de confusión, se puede evidenciar que el modelo ScoreLogisticoB predice muy mal la clase 0. Además, debido a que el interés es predecir a aquellos posibles morosos, hay un interés particular en predecir correctamente la clase 1. Luego, si se observa el valor de predicción positivo `Pos Pred Value` en ambos modelos, se puede dar cuenta que el modelo que mejor valor de predicción de la clase positiva es ScoreLogisticoA, con 63%; mientras que ScoreLogisticoA tiene un `Pos Pred Value` de 49%.

Así, el modelo que mejor predice el incumplimiento es el modelo ScoreLogisticoA. 

